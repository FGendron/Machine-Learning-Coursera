{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red> Machine Learning Course on Coursera </font>\n",
    "## Programming Exercise 4: <font color=blue>Neural Network Learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Neural Network  </font>\n",
    ">In the previous exercise, you implemented feedforward propagation for neural networks and used it to predict handwritten digits with the weights we provided. In this exercise, you will implement the backpropagation algorithm to learn the parameters for the neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# will be used to transform the y\n",
    "from pandas import get_dummies\n",
    "\n",
    "# import of my own functions\n",
    "import my_ML_functions\n",
    "#set up\n",
    "sigmoid = my_ML_functions.sigmoid\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first import the data and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20x20 Input Images of Digits\n",
    "input_layer_size  = 400\n",
    "\n",
    "# 10 labels, from 1 to 10 (note that we have mapped \"0\" to label 10)\n",
    "num_labels = 10\n",
    "\n",
    "#  training data stored in arrays X, y\n",
    "data = loadmat('Data/MultiClass-ex3data1.mat')\n",
    "X, y = data['X'], data['y'].ravel()\n",
    "\n",
    "# set the zero digit to 0, rather than its mapped 10 in this dataset\n",
    "# This is an artifact due to the fact that this dataset was used in \n",
    "# MATLAB where there is no index 0\n",
    "y[y == 10] = 0\n",
    "\n",
    "m = y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nB61BL+Z7x/EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load randomly an image of the data set\n",
    "item = np.random.randint(m)\n",
    "img = X[item]\n",
    "plt.imshow(img.reshape(20,20),cmap = plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward and Costfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the already optmized weights Theta_1 and Theta_2\n",
    "weights =loadmat('Data/NeuralNet-ex4weights.mat')\n",
    "Theta1,Theta2 = weights['Theta1'],weights['Theta2']\n",
    "# swap first and last columns of Theta2, due to legacy from MATLAB indexing, \n",
    "# since the weight file ex3weights.mat was saved based on MATLAB indexing\n",
    "Theta2 = np.roll(Theta2, 1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup nnparam: Use ravel to transfrom matrix in vectors\n",
    "nnparam = np.concatenate([Theta1.ravel(),Theta2.ravel()])\n",
    "\n",
    "# Buil my model\n",
    "input_layer_size = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnCostFunction(nnparam,input_layer_size,hidden_layer_size,num_labels,X,y,Lambda):\n",
    "    \"\"\"Calculate the neural network cost and gradient regulaized functions\n",
    "    Parameters:\n",
    "    nnparam = vector that contains the weights\n",
    "    input_layer_size = number of nodes in input layer\n",
    "    hidden_layer_size = number of nodes in hidden layer\n",
    "    num_labels = number of nodes in output layer\n",
    "    X = matrices of m x n \n",
    "    \"\"\"\n",
    "    # First reshape the weight matrices\n",
    "    Theta_1 = np.reshape(nnparam[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                     (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta_2 = np.reshape(nnparam[hidden_layer_size * (input_layer_size + 1):],\n",
    "                     (num_labels, (hidden_layer_size + 1)))\n",
    "    \n",
    "    # add ones to Xp\n",
    "    m,n = X.shape\n",
    "    ones = np.ones((m,1))\n",
    "    Xp = np.concatenate([ones,X],axis=1)\n",
    "\n",
    "    # reshape the y\n",
    "    y = get_dummies(y)\n",
    "    \n",
    "    #feedforward propagation\n",
    "    z2 = Xp.dot(Theta_1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    #a2 = np.concatenate([ones,a2],axis=1)\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    #a2.shape,Theta2.shape\n",
    "    z3 = a2.dot(Theta_2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    #regularization cost\n",
    "    reg = np.sum(np.sum(np.square(Theta_1[0:,1:]))) + np.sum(np.sum(np.square(Theta_2[0:,1:])))\n",
    "    #cost function\n",
    "    J = (-1 / m) * np.sum(np.sum(y*np.log(a3) + (1-y)*np.log(1 - a3))) + (Lambda / (2 * m)) * reg\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28762916516131876"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing you nnCostfunction\n",
    "# with Lambda = 0, Cost = 0.287629\n",
    "# with Lambda = 1, Cost = 0.383770\n",
    "Lambda = 0\n",
    "cost,grad = nnCostFunction(nnparam,input_layer_size,hidden_layer_size,num_labels,X,y,Lambda)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing BackPropagation\n",
    "In this part of the exercise, you will implement the backpropagation algorithm to compute the gradient for the neural network cost function. You will need to complete the nnCostFunction.m so that it returns an appropriate value for grad. Once you have computed the gradient, you will be able to train the neural network by minimizing the cost function J(Î˜) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_deriv(z):\n",
    "    \"\"\"Calculate the derivative of the sigmoid function\n",
    "    \"\"\"\n",
    "    sig_deriv = sigmoid(z) * (1 - sigmoid(z))\n",
    "    return sig_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnCostFunction(nnparams,input_layer_size,hidden_layer_size,num_labels,X,y,Lambda):\n",
    "    \"\"\"Calculate the neural network cost and gradient regulaized functions\n",
    "    Parameters:\n",
    "    nnparam = vector that contains the weights\n",
    "    input_layer_size = number of nodes in input layer\n",
    "    hidden_layer_size = number of nodes in hidden layer\n",
    "    num_labels = number of nodes in output layer\n",
    "    X = matrices of m x n \n",
    "    \"\"\"\n",
    "    # First reshape the weight matrices\n",
    "    Theta_1 = np.reshape(nnparams[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                     (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta_2 = np.reshape(nnparams[hidden_layer_size * (input_layer_size + 1):],\n",
    "                     (num_labels, (hidden_layer_size + 1)))\n",
    "    \n",
    "    # add ones to Xp\n",
    "    m,n = X.shape\n",
    "    ones = np.ones((m,1))\n",
    "    Xp = np.concatenate([ones,X],axis=1)\n",
    "\n",
    "    # reshape the y\n",
    "    Y = get_dummies(y)\n",
    "    \n",
    "    #feedforward propagation\n",
    "    z2 = Xp.dot(Theta_1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    #a2 = np.concatenate([ones,a2],axis=1)\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    #a2.shape,Theta2.shape\n",
    "    z3 = a2.dot(Theta_2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    #regularization cost\n",
    "    reg = np.sum(np.sum(np.square(Theta_1[0:,1:]))) + np.sum(np.sum(np.square(Theta_2[0:,1:])))\n",
    "    #cost function\n",
    "    J = (-1 / m) * np.sum(np.sum(Y*np.log(a3) + (1-Y)*np.log(1 - a3))) + (Lambda / (2 * m)) * reg\n",
    "    \n",
    "    #back propagation\n",
    "    delta_3 =  a3 - Y.values\n",
    "    delta_2 = (delta_3 @ Theta_2) * sigmoid_deriv(np.concatenate([np.ones((z2.shape[0],1)),z2[:,:]],axis=1))\n",
    "    delta_2 = delta_2[:,1:]\n",
    "    \n",
    "    Delta_2 = delta_3.T.dot(a2)\n",
    "    Delta_1 = delta_2.T.dot(Xp)\n",
    "\n",
    "    #gradients\n",
    "    temp1 = np.concatenate([np.zeros((Theta_1.shape[0],1)),Theta_1[:,1:]],axis=1)\n",
    "    temp2 = np.concatenate([np.zeros((Theta_2.shape[0],1)),Theta_2[:,1:]],axis=1)\n",
    "    \n",
    "    grad_1 = (1 / m) * Delta_1 + (Lambda / m) * temp1\n",
    "    grad_2 = (1 / m) * Delta_2 + (Lambda / m) * temp2\n",
    "    \n",
    "    grad = np.concatenate([grad_1.ravel(),grad_2.ravel()])\n",
    "\n",
    "    return J, grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeNumericalGradient(J, theta, e=1e-4):\n",
    "    \"\"\"\n",
    "    Computes the gradient using finite differences\"\n",
    "    \"\"\"\n",
    "    numgrad = np.zeros(theta.shape)\n",
    "    perturb = np.diag(e * np.ones(theta.shape))\n",
    "    for i in range(theta.size):\n",
    "        loss1, _ = J(theta - perturb[:, i])\n",
    "        loss2, _ = J(theta + perturb[:, i])\n",
    "        numgrad[i] = (loss2 - loss1)/(2*e)\n",
    "    return numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01818218 0.01818218]\n",
      " [0.01040637 0.01040637]\n",
      " [0.00706085 0.00706085]\n",
      " [0.0118763  0.0118763 ]\n",
      " [0.00874809 0.00874809]\n",
      " [0.01114942 0.01114942]\n",
      " [0.06360681 0.06360681]\n",
      " [0.03098065 0.03098065]\n",
      " [0.02419464 0.02419464]\n",
      " [0.03906456 0.03906456]\n",
      " [0.03131861 0.03131861]\n",
      " [0.04023647 0.04023647]\n",
      " [0.04432645 0.04432645]\n",
      " [0.02757561 0.02757561]\n",
      " [0.01990417 0.01990417]\n",
      " [0.0287708  0.0287708 ]\n",
      " [0.01954413 0.01954413]\n",
      " [0.02604778 0.02604778]\n",
      " [0.5982196  0.5982196 ]\n",
      " [0.4723676  0.4723676 ]\n",
      " [0.47894738 0.47894738]\n",
      " [0.4994032  0.4994032 ]\n",
      " [0.35265865 0.35265865]\n",
      " [0.27888686 0.27888686]\n",
      " [0.2865675  0.2865675 ]\n",
      " [0.29555322 0.29555322]\n",
      " [0.28692582 0.28692582]\n",
      " [0.23275119 0.23275119]\n",
      " [0.23964323 0.23964323]\n",
      " [0.25258853 0.25258853]]\n"
     ]
    }
   ],
   "source": [
    "# Build a small Neural Network to check your gradients\n",
    "input_layer_size = 5\n",
    "hidden_layer_size = 3\n",
    "num_labels = 3\n",
    "m = 5\n",
    "Lambda = 0\n",
    "\n",
    "# Generates random weights, inputs and outputs\n",
    "np.random.seed(2)\n",
    "Theta1 = np.random.rand(hidden_layer_size, input_layer_size + 1)\n",
    "Theta2 = np.random.rand(num_labels,hidden_layer_size + 1)\n",
    "\n",
    "X_t = np.random.rand(m,input_layer_size)\n",
    "y_t = np.arange(1, 1+m) % num_labels\n",
    "\n",
    "# Unroll parameters\n",
    "nnparams = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n",
    "\n",
    "# short hand for cost function\n",
    "costFunc = lambda p: nnCostFunction(p, input_layer_size, hidden_layer_size,\n",
    "                                        num_labels, X_t, y_t, Lambda)\n",
    "\n",
    "# Calculate the gradients with your nnCostFunction and the finite size gradients\n",
    "cost, grad = costFunc(nnparams)\n",
    "numgrad = computeNumericalGradient(costFunc,nnparams)\n",
    "\n",
    "# Compare the results of the two codes: Should be almost exactly the same\n",
    "print(np.stack([numgrad,grad], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network\n",
    "> You can play with the Lambda value and with the number of nodes in the hidden layer to improve the accuracy of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data stored in arrays X, y\n",
    "data = loadmat('Data/MultiClass-ex3data1.mat')\n",
    "X, y = data['X'], data['y'].ravel()\n",
    "\n",
    "# set the zero digit to 0, rather than its mapped 10 in this dataset\n",
    "# This is an artifact due to the fact that this dataset was used in \n",
    "# MATLAB where there is no index 0\n",
    "y[y == 10] = 0\n",
    "\n",
    "# Build my model\n",
    "input_layer_size = 400\n",
    "hidden_layer_size = 100\n",
    "num_labels = 10\n",
    "Lambda = 1\n",
    "\n",
    "# random Initialization of the weights\n",
    "np.random.seed(1)\n",
    "Theta1 = 2*np.random.rand(hidden_layer_size,input_layer_size + 1) - 1\n",
    "Theta2 = 2*np.random.rand(num_labels,hidden_layer_size + 1) - 1\n",
    "\n",
    "# Setup nnparam: Use ravel to transfrom matrix in vectors\n",
    "nnparam = np.concatenate([Theta1.ravel(),Theta2.ravel()],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has my optimization converged ? False\n",
      "What is the func score ? 1.0079815739564881\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "options = {'maxiter': 100}\n",
    "comp = optimize.minimize(nnCostFunction,nnparam,(input_layer_size,hidden_layer_size,num_labels,X,y,Lambda),\n",
    "                 jac=True,method='TNC',options=options)\n",
    "\n",
    "# Reshape the optimized weights\n",
    "Theta1_opt = np.reshape(comp.x[:hidden_layer_size*(input_layer_size+1)],\n",
    "                        (hidden_layer_size,(input_layer_size +1)))\n",
    "Theta2_opt = np.reshape(comp.x[hidden_layer_size*(input_layer_size+1):],\n",
    "                        (num_labels,(hidden_layer_size +1)))\n",
    "comp.success\n",
    "comp\n",
    "print('Has my optimization converged ?',comp.success)\n",
    "print('What is the func score ?',comp.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you modify the number of iterations in the optimizer and you setup Lambda = 1, you can reach an accuracy of almost 100% for you neural network. A good case of overfitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.82"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy your Optimized Neural Net\n",
    "# add ones to Xp\n",
    "m,n = X.shape\n",
    "ones = np.ones((m,1))\n",
    "Xp = np.concatenate([ones,X],axis=1)\n",
    "    \n",
    "#feedforward propagation\n",
    "z2 = Xp.dot(Theta1_opt.T)\n",
    "a2 = sigmoid(z2)\n",
    "#a2 = np.concatenate([ones,a2],axis=1)\n",
    "a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "#a2.shape,Theta2.shape\n",
    "z3 = a2.dot(Theta2_opt.T)\n",
    "a3 = sigmoid(z3)\n",
    "\n",
    "# Accuracy of the Neural Net\n",
    "prediction = np.argmax(a3,axis=1)\n",
    "prediction\n",
    "accuracy = np.mean(prediction == y) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize your Neural Net Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Neural Network prediction is a 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nBKEAIEEoAEj8H7YV0JxdJ5oNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select a random image among the data set\n",
    "item = np.random.randint(m)\n",
    "#\n",
    "# What is the prediction of the Neural Net\n",
    "print('My Neural Network prediction is a',prediction[item])\n",
    "# plot the random image\n",
    "img = X[item]\n",
    "plt.imshow(img.reshape(20,20),cmap = plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualize the Hidden layer of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the hidden node 16 sees\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select a random image among the data set\n",
    "item = np.random.randint(hidden_layer_size)\n",
    "#\n",
    "# What is the prediction of the Neural Net\n",
    "print('This is what the hidden node',item,'sees')\n",
    "# plot the random image\n",
    "img = Theta1_opt[item,1:]\n",
    "plt.imshow(img.reshape(20,20),cmap = plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each hidden units is looking for one specific patern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do it with Keras !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples is of  5000\n"
     ]
    }
   ],
   "source": [
    "#Let's import again the data to avoid problems\n",
    "# training data stored in arrays X, y\n",
    "data = loadmat('Data/MultiClass-ex3data1.mat')\n",
    "X, y = data['X'], data['y'].ravel()\n",
    "\n",
    "# set the zero digit to 0, rather than its mapped 10 in this dataset\n",
    "# This is an artifact due to the fact that this dataset was used in \n",
    "# MATLAB where there is no index 0\n",
    "y[y == 10] = 0\n",
    "\n",
    "Y = to_categorical(y) # convert your y's into vectors like the get_dummies functions (super important !)\n",
    "\n",
    "m,n = X.shape\n",
    "print('The number of training examples is of ',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 1ms/step - loss: 0.0999 - accuracy: 0.2753\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0718 - accuracy: 0.5883\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0517 - accuracy: 0.7408: \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0405 - accuracy: 0.8280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0337 - accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0299 - accuracy: 0.8722\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0262 - accuracy: 0.8840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0234 - accuracy: 0.8928\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0222 - accuracy: 0.8996\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0213 - accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "# Build the model: 3 layers input (400 nodes), hidden (25 nodes), output (10 nodes)\n",
    "model = Sequential([\n",
    "  Dense(25, activation='sigmoid', input_shape=(400,)),\n",
    "  Dense(10, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "sgd = optimizers.SGD(lr=0.5)\n",
    "model.compile(\n",
    "  optimizer=sgd, #another choice is adam\n",
    "  #optimizer='adam',\n",
    "  loss='mean_squared_error', # another choice is categorical_crossentropy\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(\n",
    "  X, # training data\n",
    "  Y, # training targets\n",
    "  epochs=10,\n",
    "  batch_size=5, #divide your data set in n batches\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now deploy the trained neural net !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Neural Network prediction is a 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\nbGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsT\nAAALEwEAmpwYAAAQ70lEQVR4nO3df4xVZX7H8c/HYWgCIoIIIr/WUDShplI1bEktwbprgeiyW3EL\nMZa1VuxGosRqY1t/bOw/qwY1XYjU3SW4Zhe1teySLFWJbWQ17OqgiLIuFQmGYVkoalF0CQ58+8ec\n2cwz3AvP/TFz7wzvV0Luued87znPdeDjuec+c76OCAFAl9MaPQAAzYVQAJAgFAAkCAUACUIBQGJQ\nowdQyqhRo2LSpEmNHgYwYL3//vs6cOCAS21rylCYNGmSNm3a1OhhAAPWjBkzym7j4wOARE2hYHu2\n7e22d9i+q8T237P9dLH9F7a/UMvxAPS+qkPBdoukFZLmSJoqaaHtqT3KbpT0UUT8vqRHJD1Q7fEA\n9I1azhSmS9oRETsj4oikpyTN61EzT9ITxfK/S7rCdsmLGwCaQy2hME7S7m7P24t1JWsiokPSQUln\nldqZ7cW222y3HThwoIZhAahF01xojIjHI+LSiLh01KhRjR4OcMqqJRT2SJrQ7fn4Yl3JGtuDJA2X\n9EENxwTQy2oJhdckTbF9nu3BkhZIWtejZp2kRcXyfEn/FfyuNtDUqp68FBEdtpdIel5Si6RVEbHN\n9v2S2iJinaTvS3rS9g5JH6ozOAA0sZpmNEbEeknre6y7t9vyYUnX1nIMAH2raS40AmgOhAKABKEA\nIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKABKEAIEEoAEgQCgAShAKA\nRC0doibY/m/bv7S9zfZtJWpm2T5oe0vx595S+wLQPGq5R2OHpL+LiNdtD5O02faGiPhlj7qfRcRV\nNRwHQB+q+kwhIvZGxOvF8ieS3tHxHaIA9DN1uaZQdJP+I0m/KLF5hu03bf+n7T84wT5oGwc0gZpD\nwfbpkp6VtDQiPu6x+XVJkyLiIknfkfTjcvuhbRzQHGoKBdut6gyEH0bEf/TcHhEfR8ShYnm9pFbb\n/IsHmlgt3z5YnR2g3omIh8vUnNPVet729OJ49JIEmlgt3z78iaTrJb1le0ux7h8lTZSkiFipzv6R\n37TdIem3khbQSxJobrX0knxZkk9Ss1zS8mqPAaDvMaMRQIJQAJAgFAAkCAUACUIBQKKWryTRDxXT\nRuqOb5oHDs4UACQIBQAJQgFAglAAkCAUACQIBQAJQgFAglAAkCAUACSY0diHWlpasmsrmSFYSe3n\nn3+eXdva2ppdW8lMyf40+/G003rn/5vHjh3rlf3WA2cKABKEAoBEPW7xvsv2W0VbuLYS2237X2zv\nsL3V9sW1HhNA76nXNYXLI6JcB5c5kqYUf74o6bHiEUAT6ouPD/Mk/SA6/VzSmbbH9sFxAVShHqEQ\nkl6wvdn24hLbx0na3e15u0r0nKRtHNAc6hEKl0XExer8mHCL7ZnV7IS2cUBzqDkUImJP8bhf0lpJ\n03uU7JE0odvz8cU6AE2o1l6SQ20P61qWdKWkt3uUrZP0V8W3EH8s6WBE7K3luAB6T63fPoyRtLaY\nzTZI0o8i4jnbfyv9rnXceklzJe2Q9JmkG2o8JoBeVFMoRMROSReVWL+y23JIuqWW4zS73Cm+77zz\nTvY+x48fn1370ksvZdc+++yz2bUTJ07Mrr399tuza4cPH55dW8l04EqmWufW7t2bf1JbyRTySn6+\nfT0tnBmNABKEAoAEoQAgQSgASBAKABKEAoAEoQAgQSgASBAKABKEAoAEd3MuY9Cg/P80Dz74YFbd\nsmXLsvc5evTo7Np9+/Zl137yySfZtZXcyfjJJ5/Mrr3pppuya++4447s2kOHDmXXLl26NKvulVde\nyd7n0aNHs2tXrFiRXTtnzpzs2nrcJZozBQAJQgFAglAAkCAUACQIBQAJQgFAglAAkKg6FGxfULSK\n6/rzse2lPWpm2T7YrebemkcMoFdVPXkpIrZLmiZJtlvUedv2tSVKfxYRV1V7HAB9q14fH66Q9F5E\nvF+n/QFokHpNc14gaU2ZbTNsvynp15LuiIhtpYqKlnOLpcruIlyJSqbtVjIdOHcq7MGDB7P3WcmU\n3UqmRK9evTq7tpIps/fem//JcPny5dm1H330UXbttm0l/2qVlNuacMmSJdn7zJ3uLlV2V+25c+dm\n19ZDPVrRD5b0FUn/VmLz65ImRcRFkr4j6cfl9kPbOKA51OPjwxxJr0fEcb+VExEfR8ShYnm9pFbb\n/IsHmlg9QmGhynx0sH2Oi64btqcXx/ugDscE0EtquqZQ9I/8sqSbu63r3jJuvqRv2u6Q9FtJC6Kv\n290AqEitbeM+lXRWj3XdW8Ytl5R/VQlAwzGjEUCCUACQIBQAJAgFAAlCAUDilLqbczFlIkvuNFhJ\nam9vz6p74IEHsve5cePG7NrTTz89u7aSOwO3tLRk106ePDm7dv78+dm1Dz/8cHbt2LFjs2s3bNiQ\nVXf++edn73PLli3Zta+++mp2bV/jTAFAglAAkCAUACQIBQAJQgFAglAAkCAUACQIBQAJQgFAglAA\nkDilpjlXMm33jTfeyK7dvn17Vt21116bvc/du3dn155xxhnZtZU4evRodm1ra2t2bSXTsivxwQf5\nd/rbunVrVt2QIUOy91nJHcCbGWcKABJZoWB7le39tt/utm6k7Q223y0eR5R57aKi5l3bi+o1cAC9\nI/dMYbWk2T3W3SXpxYiYIunF4nnC9khJ90n6oqTpku4rFx4AmkNWKETERkkf9lg9T9ITxfITkr5a\n4qV/LmlDRHwYER9J2qDjwwVAE6nlmsKYiNhbLP9G0pgSNeMkdb9i1l6sA9Ck6nKhsejlUFM/B9uL\nbbfZbqvkBicA6quWUNhne6wkFY/7S9TskTSh2/Pxxbrj0EsSaA61hMI6SV3fJiyS9JMSNc9LutL2\niOIC45XFOgBNKvcryTWSNkm6wHa77RslfVvSl22/K+lLxXPZvtT29yQpIj6U9M+SXiv+3F+sA9Ck\nsmY0RsTCMpuuKFHbJulvuj1fJWlVVaMD0OdOqWnOlejo6OiV2lwzZ87Mrv3000+za3vrjtY33HBD\ndm0l07Lvvvvu7No1a0o2Py/puuuuy6o755xzsve5d+/ekxcVbr311uzavsY0ZwAJQgFAglAAkCAU\nACQIBQAJQgFAglAAkCAUACQIBQAJQgFA4pSa5tx524c8lUxvHT58eFbd4cOHs/d59dVXZ9dWctfl\nQ4cOZdfeeeed2bWDBw/Orl21Kv9XYcaPH59dO3/+/OzapUuXZtW999572fu88MILs2tvu+227NpK\n/t7WA2cKABKEAoAEoQAgQSgASBAKABKEAoAEoQAgcdJQKNNH8iHbv7K91fZa22eWee0u22/Z3mK7\nrY7jBtBLcs4UVuv4Vm8bJF0YEX8o6X8k/cMJXn95REyLiEurGyKAvnTSUCjVRzIiXoiIrruV/lyd\nTV4ADAD1mOb815KeLrMtJL1gOyT9a0Q8Xm4nthdLWixJEydOrMOwjnfs2LHs2smTJ2fXjhuX1x7z\nnnvuyd7n9ddfX/fjS9Kjjz6aXTty5Mjs2oceeii79qyzzsqureRnVsk042eeeSar7rPPPsve52mn\n5V+iGz16dHZtJf8N6qGmC422/0lSh6Qflim5LCIuljRH0i22y963nLZxQHOoOhRsf0PSVZKuizK/\nsRERe4rH/ZLWSppe7fEA9I2qQsH2bEl/L+krEVHy/Mr2UNvDupbV2Ufy7VK1AJpHzleSpfpILpc0\nTNKG4uvGlUXtubbXFy8dI+ll229KelXSTyPiuV55FwDq5qQXGsv0kfx+mdpfS5pbLO+UdFFNowPQ\n55jRCCBBKABIEAoAEoQCgAShACBxSt3NuZLpomeffXZ27TXXXJNVt3Llyux9btu2Lbu2kqm4c+fO\nza69//77s2uHDBmSXVvJ3acrUcl+R4wYUde6SvX11OVKcKYAIEEoAEgQCgAShAKABKEAIEEoAEgQ\nCgAShAKABKEAIOEyd1JrqEsuuSQ2bdrU0DHYzq7NnUl3+PDhaodzQkeOHMmuHTZsWHZta2trdm0z\nz9DD8WbMmKHNmzeX/EvOmQKABKEAIFFt27hv2d5T3J9xi+2Sv2Vje7bt7bZ32L6rngMH0DuqbRsn\nSY8U7eCmRcT6nhttt0haoc6eD1MlLbQ9tZbBAuh9VbWNyzRd0o6I2BkRRyQ9JWleFfsB0Idquaaw\npOg6vcp2qV86Hydpd7fn7cW6kmwvtt1mu+3AgQM1DAtALaoNhcckTZY0TdJeSctqHQht44DmUFUo\nRMS+iDgaEcckfVel28HtkTSh2/PxxToATazatnFjuz39mkq3g3tN0hTb59keLGmBpHXVHA9A3znp\nPRqLtnGzJI2y3S7pPkmzbE9TZ6v5XZJuLmrPlfS9iJgbER22l0h6XlKLpFURkX/jQQAN0Wtt44rn\n6yUd93Vlf1DJ9O+WlpasuqFDh1Y7nIbsl6nLpyZmNAJIEAoAEoQCgAShACBBKABIEAoAEoQCgASh\nACBBKABIEAoAEied5oyTa8Y7YgPV4kwBQIJQAJAgFAAkCAUACUIBQIJQAJAgFAAkcu7RuErSVZL2\nR8SFxbqnJV1QlJwp6f8iYlqJ1+6S9Imko5I6IuLSuowaQK/Jmby0WtJyST/oWhERf9m1bHuZpIMn\neP3lEUF3F6CfyLlx60bbXyi1zbYlfV3Sn9V5XAAapNZrCn8qaV9EvFtme0h6wfZm24tPtCPaxgHN\nodZQWChpzQm2XxYRF6uz8/QttmeWK6RtHNAcqg4F24Mk/YWkp8vVRMSe4nG/pLUq3V4OQBOp5Uzh\nS5J+FRHtpTbaHmp7WNeypCtVur0cgCZy0lAo2sZtknSB7XbbNxabFqjHRwfb59ru6gg1RtLLtt+U\n9Kqkn0bEc/UbOoDeUG3bOEXEN0qs+13buIjYKemiGscHoI8xoxFAglAAkCAUACQIBQAJQgFAglAA\nkCAUACQIBQAJQgFAglAAkCAUACQIBQAJQgFAglAAkCAUACQIBQAJR0Sjx3Ac2/8r6f0eq0dJGoi3\neR6o70sauO9tILyvSRFxdqkNTRkKpdhuG4gdpgbq+5IG7nsbqO+rCx8fACQIBQCJ/hQKjzd6AL1k\noL4vaeC+t4H6viT1o2sKAPpGfzpTANAHCAUAiX4RCrZn295ue4ftuxo9nnqxvcv2W7a32G5r9Hhq\nYXuV7f223+62bqTtDbbfLR5HNHKM1Sjzvr5le0/xc9tie24jx1hvTR8KtlskrVBn5+qpkhbantrY\nUdXV5RExbQB8771a0uwe6+6S9GJETJH0YvG8v1mt49+XJD1S/NymRcT6Etv7raYPBXV2qt4RETsj\n4oikpyTNa/CY0ENEbJT0YY/V8yQ9USw/IemrfTmmeijzvga0/hAK4yTt7va8vVg3EISkF2xvtr24\n0YPpBWMiYm+x/Bt1Nh0eKJbY3lp8vOh3H4tOpD+EwkB2WURcrM6PRrfYntnoAfWW6Pzue6B8//2Y\npMmSpknaK2lZQ0dTZ/0hFPZImtDt+fhiXb8XEXuKx/2S1qrzo9JAss/2WEkqHvc3eDx1ERH7IuJo\nRByT9F0NsJ9bfwiF1yRNsX2e7cGSFkha1+Ax1cz2UNvDupYlXSnp7RO/qt9ZJ2lRsbxI0k8aOJa6\n6Qq6wtc0wH5ugxo9gJOJiA7bSyQ9L6lF0qqI2NbgYdXDGElrbUudP4cfRcRzjR1S9WyvkTRL0ijb\n7ZLuk/RtSc/YvlGdvwr/9caNsDpl3tcs29PU+XFol6SbGzW+3sA0ZwCJ/vDxAUAfIhQAJAgFAAlC\nAUCCUACQIBQAJAgFAIn/B8he4yj+LzEuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select a random image among the data set\n",
    "item = np.random.randint(m)\n",
    "#\n",
    "# What is the prediction of the Neural Net\n",
    "nnPredict = np.argmax(model.predict(X[item].reshape(1,-1)))\n",
    "print('My Neural Network prediction is a',nnPredict)\n",
    "# plot the random image\n",
    "img = X[item]\n",
    "plt.imshow(img.reshape(20,20),cmap = plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
